{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:35.779113Z",
     "start_time": "2018-05-16T08:43:33.344615Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import sys\n",
    "import tempfile\n",
    "from dateutil import tz\n",
    "\n",
    "from ratschlab_common.io.bigmatrix import TablesBigMatrixReader, TablesBigMatrixWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Matrix Usage Example\n",
    "\n",
    "`Bigmatrix` represents an abstraction for out-of-core computation with large\n",
    "matrices having some 'metadata' associated with the rows and columns. This\n",
    "metadata can be for example some patient id and a timestamp for the rows\n",
    "and a column name for each column, e.g. the name of features. The matrix itself\n",
    "could represent the values of the features for patients at different times.\n",
    "\n",
    "The motivation behind this abstraction is, that sometimes a dataset can be almost\n",
    "represented as a matrix, i.e. has the same datatype across all columns, typically\n",
    "some float or int. But a few columns represent something else, e.g. time information\n",
    "or ids. The idea is to handle these metadata separately from the rest. This way\n",
    "the entire dataset can be handled more efficiently and easily.\n",
    "\n",
    "`ratschlab_common.io.bigmatrix` serializes all the data to disk using HDF5 via the `pytables` library. A file generated by this module consists of three nodes: one for the matrix, one for the column description and one for the row description. The matrix is written directly by `pytables` whereas the metadata is written by `pandas`. This can be changed to `pytables` as well, for example in case `pandas` would use too much memory for processing the metadata.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:48:52.733583Z",
     "start_time": "2018-05-15T09:48:52.727914Z"
    }
   },
   "source": [
    "## Generating Fake Data\n",
    "\n",
    "First, we'll generate some fake data and write it incrementally using `TablesBigMatrixWriter`.\n",
    "\n",
    "The fake data consists of numerical records of several patients, where each record has a timestamp and a patient id associated. These two columns are stored as row descriptions (i.e. a dataframe). \n",
    "\n",
    "Note, that in principle, the time information could be integrated into the numerical matrix. However, indexing and time zone handling etc would have to be done manually. In this approach, we let `pandas` take care of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:35.787913Z",
     "start_time": "2018-05-16T08:43:35.782090Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42**2 # make it deterministic (at least when running from top to bottom)\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "## config:\n",
    "num_patients = 50\n",
    "patient_ids = np.random.randint(100000, size=num_patients)\n",
    "\n",
    "rows_per_patient = 1000\n",
    "cols = 150\n",
    "\n",
    "start_date = datetime.datetime(2018, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:35.805420Z",
     "start_time": "2018-05-16T08:43:35.790868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05587935447692871"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size_in_memory = 8*num_patients*rows_per_patient*cols/1024**3 #GB\n",
    "data_size_in_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:35.816703Z",
     "start_time": "2018-05-16T08:43:35.808233Z"
    }
   },
   "outputs": [],
   "source": [
    "def fake_patient_data(pid, rows, cols):\n",
    "    \"\"\"\n",
    "    Generates fake data for one patient with a given patient id\n",
    "    \"\"\"\n",
    "    ids = np.full((rows,), pid)\n",
    "    \n",
    "    # a measurement all 5 minutes\n",
    "    timestamps = pd.date_range(pd.to_datetime(start_date), periods=rows, freq='5min')\n",
    "    \n",
    "    row_desc = pd.DataFrame.from_dict({'id' : ids, 'ts' : timestamps})\n",
    "    \n",
    "    data = np.random.uniform(size=(rows, cols)) + pid # biasing the values, s.t. we know we got the data from the right patient\n",
    "    \n",
    "    return data, row_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:35.828549Z",
     "start_time": "2018-05-16T08:43:35.819989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/var/folders/ry/d9fpyr5d21xgbjyrl084ssqh0000gn/T/tmp1gs7pni_/fake_patient_data.h5')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "output_path = Path(temp_dir.name, 'fake_patient_data.h5')\n",
    "output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also columns can be described using a data frame. Typically, it would contain just the column name. Here we add also some comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:35.865937Z",
     "start_time": "2018-05-16T08:43:35.831745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You could additionally also add some comment f...</td>\n",
       "      <td>my_col0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You could additionally also add some comment f...</td>\n",
       "      <td>my_col1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You could additionally also add some comment f...</td>\n",
       "      <td>my_col2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You could additionally also add some comment f...</td>\n",
       "      <td>my_col3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You could additionally also add some comment f...</td>\n",
       "      <td>my_col4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment     name\n",
       "0  You could additionally also add some comment f...  my_col0\n",
       "1  You could additionally also add some comment f...  my_col1\n",
       "2  You could additionally also add some comment f...  my_col2\n",
       "3  You could additionally also add some comment f...  my_col3\n",
       "4  You could additionally also add some comment f...  my_col4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_desc = pd.DataFrame(\n",
    "    {'name': [\"my_col{}\".format(c) for c in range(0, cols)],\n",
    "     'comment': [\"You could additionally also add some comment for column {}\".format(c) for c in range(0, cols)]\n",
    "    })\n",
    "\n",
    "col_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to allow efficient access and compression when writing to disk using HDF5, data can be split into \"chunks\".\n",
    "See also https://support.hdfgroup.org/HDF5/doc/Advanced/Chunking/index.html\n",
    "\n",
    "Poorly chosen chunksizes/shapes can have a significantly negative impact on performance, so it's usually worth experimenting a bit.\n",
    "\n",
    "In general, when writing HDF5 files incrementally, it is important to select a chunksize/shape manually, as otherwise the HDF5 library (e.g. pytables) may choose an inappropriate size depending on the first data written.\n",
    "\n",
    "For some advice on how to choose the chunksize, see http://www.pytables.org/usersguide/optimization.html#understanding-chunking\n",
    "Since blosc compression is currently used as default one should aim at something in the ballpark of 500kb of data per chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:35.877238Z",
     "start_time": "2018-05-16T08:43:35.871276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkshape = (1000, 50) # nicely aligned with the fake data (doesn't need to be the case)\n",
    "\n",
    "chunksize_kb = np.dtype('float').itemsize * chunkshape[0] * chunkshape[1]/1024\n",
    "chunksize_kb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:59:30.584086Z",
     "start_time": "2018-05-15T10:59:30.577816Z"
    }
   },
   "source": [
    "Since we assume we are dealing with a lot of data, we are going to write the patient data sequentially.\n",
    "\n",
    "Note, that only rows can be appended, but not columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:37.306893Z",
     "start_time": "2018-05-16T08:43:35.880896Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = TablesBigMatrixWriter()\n",
    "\n",
    "if output_path.exists():\n",
    "    output_path.unlink()\n",
    "    \n",
    "for pid in patient_ids:\n",
    "    data, row_desc = fake_patient_data(pid, rows_per_patient, cols)\n",
    "    \n",
    "    writer.write_or_append(output_path, data, row_desc, col_desc, chunkshape=chunkshape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:37.444423Z",
     "start_time": "2018-05-16T08:43:37.309760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 marc  staff  38409242 May 16 10:43 /var/folders/ry/d9fpyr5d21xgbjyrl084ssqh0000gn/T/tmp1gs7pni_/fake_patient_data.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l $output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:17:32.224120Z",
     "start_time": "2018-05-16T08:17:32.216119Z"
    }
   },
   "source": [
    "Below the groups in the newly created HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:38.285442Z",
     "start_time": "2018-05-16T08:43:37.450650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/data (EArray(50000, 150), fletcher32, shuffle, blosc:lz4(5)) ''\n",
      "/col_descr (Group) ''\n",
      "/col_descr/table (Table(150,), shuffle, blosc:lz4(5)) ''\n",
      "/row_descr (Group) ''\n",
      "/row_descr/table (Table(50000,), shuffle, blosc:lz4(5)) ''\n"
     ]
    }
   ],
   "source": [
    "!ptdump $output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T08:16:30.951913Z",
     "start_time": "2018-04-06T08:16:30.915373Z"
    }
   },
   "source": [
    "## Reading Back Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:38.300843Z",
     "start_time": "2018-05-16T08:43:38.291775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26710"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading back data of a \"random\" patient\n",
    "some_id = patient_ids[-1]\n",
    "some_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:38.371195Z",
     "start_time": "2018-05-16T08:43:38.305302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26710.20143677, 26710.55182748, 26710.87855975, ...,\n",
       "        26710.81713081, 26710.73815005, 26710.11845951],\n",
       "       [26710.78651242, 26710.69449985, 26710.29312988, ...,\n",
       "        26710.6971596 , 26710.43853235, 26710.15546655],\n",
       "       [26710.84996235, 26710.45633331, 26710.99427889, ...,\n",
       "        26710.87577065, 26710.38067227, 26710.93668617],\n",
       "       ...,\n",
       "       [26710.3633043 , 26710.80679326, 26710.86311316, ...,\n",
       "        26710.04492171, 26710.37460093, 26710.53402499],\n",
       "       [26710.65226909, 26710.07424714, 26710.88747023, ...,\n",
       "        26710.22762388, 26710.1339891 , 26710.48514644],\n",
       "       [26710.02089059, 26710.13063079, 26710.80944825, ...,\n",
       "        26710.5185127 , 26710.93133834, 26710.50079785]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all the data of some patient\n",
    "with TablesBigMatrixReader(output_path) as reader:\n",
    "    # first getting the row indices of the data belonging to the given patient\n",
    "    row_indices = reader.get_row_indices('id == {}'.format(some_id))\n",
    "    \n",
    "    # accessing the matrix\n",
    "    data_tmp = reader[row_indices, :]\n",
    "data_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T14:45:19.739030Z",
     "start_time": "2018-04-11T14:45:19.701440Z"
    }
   },
   "source": [
    "We can also get data on a specific day. The code uses pandas' `dataframe.query` function. Query syntax is a bit cumbersome...\n",
    "\n",
    "Note that '2018-03-02' implicitly gets converted to '2018-03-02 00:00:00' local time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:38.431276Z",
     "start_time": "2018-05-16T08:43:38.373957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49289   2018-03-02 00:05:00\n",
       " 49290   2018-03-02 00:10:00\n",
       " 49291   2018-03-02 00:15:00\n",
       " 49292   2018-03-02 00:20:00\n",
       " 49293   2018-03-02 00:25:00\n",
       " 49294   2018-03-02 00:30:00\n",
       " 49295   2018-03-02 00:35:00\n",
       " 49296   2018-03-02 00:40:00\n",
       " 49297   2018-03-02 00:45:00\n",
       " Name: ts, dtype: datetime64[ns],\n",
       " array([[26710.90660873, 26710.8418034 , 26710.71130172, ...,\n",
       "         26710.28144534, 26710.50091314, 26710.55610162],\n",
       "        [26710.72233082, 26710.00978424, 26710.93947081, ...,\n",
       "         26710.28969285, 26710.95075967, 26710.31592936],\n",
       "        [26710.22408737, 26710.19909297, 26710.86823822, ...,\n",
       "         26710.44479405, 26710.02135051, 26710.70572147],\n",
       "        ...,\n",
       "        [26710.312206  , 26710.72083411, 26710.4207162 , ...,\n",
       "         26710.16075147, 26710.0129967 , 26710.90915809],\n",
       "        [26710.40858287, 26710.4680696 , 26710.54513204, ...,\n",
       "         26710.82508201, 26710.99749598, 26710.82239922],\n",
       "        [26710.41591162, 26710.45859962, 26710.34461571, ...,\n",
       "         26710.86537393, 26710.53132655, 26710.16765669]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with TablesBigMatrixReader(output_path) as reader:\n",
    "    row_indices = reader.get_row_indices(\"id == {} & ts >= '2018-03-02' & ts < '2018-03-03'\".format(some_id))\n",
    "    \n",
    "    row_desc = reader.row_desc()\n",
    "    timestamps = row_desc.loc[row_indices, 'ts']\n",
    "    \n",
    "    data_tmp = reader[row_indices, :]\n",
    "timestamps[1:10], data_tmp[1:10, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:38.483995Z",
     "start_time": "2018-05-16T08:43:38.434322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26710.29889554, 26710.66328001],\n",
       "       [26710.38902207, 26710.82468611],\n",
       "       [26710.91017141, 26710.85773244],\n",
       "       ...,\n",
       "       [26710.9989812 , 26710.22916032],\n",
       "       [26710.85948349, 26710.57984862],\n",
       "       [26710.30660865, 26710.45473952]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting only a few columns of data for some patient\n",
    "with TablesBigMatrixReader(output_path) as reader:\n",
    "    row_indices = reader.get_row_indices('id == {}'.format(some_id))\n",
    "    col_indices = reader.get_col_indices_by_name(['my_col5', 'my_col6'])\n",
    "    \n",
    "    data_tmp = reader[row_indices, col_indices]\n",
    "data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:38.555202Z",
     "start_time": "2018-05-16T08:43:38.486963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40353.499702672576"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the median over an entire column (i.e. over all patients)\n",
    "with TablesBigMatrixReader(output_path) as reader:\n",
    "    col_indices = reader.get_col_indices_by_name(['my_col7'])\n",
    "    \n",
    "    col_median = np.median(reader[:, col_indices])\n",
    "col_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:43:38.566227Z",
     "start_time": "2018-05-16T08:43:38.557913Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_dir.cleanup()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
